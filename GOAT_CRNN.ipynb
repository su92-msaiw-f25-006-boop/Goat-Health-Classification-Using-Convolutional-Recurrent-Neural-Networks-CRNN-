{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jFYdpvE7Vh6Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef845634-8a33-45e1-d02f-2f1074165215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, BatchNormalization, Dense, Dropout, Input, GRU\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "DATA_ZIP_PATH = \"/content/drive/MyDrive/GoatDataset.zip\"\n",
        "EXTRACT_DIR = \"/content/drive/MyDrive/GoatDataset\"\n",
        "\n",
        "with zipfile.ZipFile(DATA_ZIP_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(EXTRACT_DIR)\n",
        "print(\"âœ… Dataset unzipped successfully\")\n",
        "\n",
        "# Original folders\n",
        "ORIGINAL_HEALTHY = os.path.join(EXTRACT_DIR, \"healthy_goat\")\n",
        "ORIGINAL_UNHEALTHY = os.path.join(EXTRACT_DIR, \"unhealthy_goat\")\n",
        "\n",
        "# Split folders\n",
        "BASE_DIR = \"/content/drive/MyDrive/Goat_Splits\"\n",
        "TRAIN_DIR = os.path.join(BASE_DIR, \"train\")\n",
        "VAL_DIR = os.path.join(BASE_DIR, \"val\")\n",
        "TEST_DIR = os.path.join(BASE_DIR, \"test\")\n",
        "\n",
        "for folder in [TRAIN_DIR, VAL_DIR, TEST_DIR]:\n",
        "    for cls in [\"healthy_goat\", \"unhealthy_goat\"]:\n",
        "        os.makedirs(os.path.join(folder, cls), exist_ok=True)\n",
        "\n",
        "# Function to split data\n",
        "def split_data(source_dir, train_dir, val_dir, test_dir, split=(0.7, 0.15, 0.15)):\n",
        "    files = os.listdir(source_dir)\n",
        "    random.shuffle(files)\n",
        "    n_total = len(files)\n",
        "    n_train = int(split[0]*n_total)\n",
        "    n_val = int(split[1]*n_total)\n",
        "\n",
        "    for i, file in enumerate(files):\n",
        "        src_path = os.path.join(source_dir, file)\n",
        "        if i < n_train:\n",
        "            dst_path = os.path.join(train_dir, file)\n",
        "        elif i < n_train + n_val:\n",
        "            dst_path = os.path.join(val_dir, file)\n",
        "        else:\n",
        "            dst_path = os.path.join(test_dir, file)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "split_data(ORIGINAL_HEALTHY,\n",
        "           os.path.join(TRAIN_DIR, \"healthy_goat\"),\n",
        "           os.path.join(VAL_DIR, \"healthy_goat\"),\n",
        "           os.path.join(TEST_DIR, \"healthy_goat\"))\n",
        "\n",
        "split_data(ORIGINAL_UNHEALTHY,\n",
        "           os.path.join(TRAIN_DIR, \"unhealthy_goat\"),\n",
        "           os.path.join(VAL_DIR, \"unhealthy_goat\"),\n",
        "           os.path.join(TEST_DIR, \"unhealthy_goat\"))\n",
        "\n",
        "print(\"âœ… Train/Val/Test splits created\")\n"
      ],
      "metadata": {
        "id": "wm_5vn5NV1c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12f2280-e517-4d97-b3eb-4d2c12c4b279"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dataset unzipped successfully\n",
            "âœ… Train/Val/Test splits created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_dataset_splits(base_dir):\n",
        "    print(f\"Checking dataset in: {base_dir}\\n\")\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        split_dir = os.path.join(base_dir, split)\n",
        "        print(f\"--- {split.upper()} ---\")\n",
        "        for cls in os.listdir(split_dir):\n",
        "            cls_dir = os.path.join(split_dir, cls)\n",
        "            num_files = len(os.listdir(cls_dir))\n",
        "            print(f\"{cls}: {num_files} images\")\n",
        "        print()\n",
        "\n",
        "# Run the check\n",
        "check_dataset_splits(BASE_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-rGm1eMijOU",
        "outputId": "5cd49839-c4d1-46e7-925d-0a57e07f9717"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking dataset in: /content/drive/MyDrive/Goat_Splits\n",
            "\n",
            "--- TRAIN ---\n",
            "healthy_goat: 312 images\n",
            "unhealthy_goat: 341 images\n",
            "\n",
            "--- VAL ---\n",
            "healthy_goat: 66 images\n",
            "unhealthy_goat: 73 images\n",
            "\n",
            "--- TEST ---\n",
            "healthy_goat: 68 images\n",
            "unhealthy_goat: 74 images\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load datasets\n",
        "train_ds = image_dataset_from_directory(\n",
        "    TRAIN_DIR, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', seed=42\n",
        ")\n",
        "val_ds = image_dataset_from_directory(\n",
        "    VAL_DIR, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', seed=42\n",
        ")\n",
        "test_ds = image_dataset_from_directory(\n",
        "    TEST_DIR, image_size=IMG_SIZE, batch_size=BATCH_SIZE, label_mode='categorical', shuffle=False\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(\"Detected Classes:\", class_names)\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.Rescaling(1./255),\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomZoom(0.2),\n",
        "    tf.keras.layers.RandomContrast(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1)\n",
        "])\n",
        "\n",
        "train_ds = train_ds.map(lambda x, y: (data_augmentation(x), y))\n",
        "val_ds = val_ds.map(lambda x, y: (x/255.0, y))\n",
        "test_ds = test_ds.map(lambda x, y: (x/255.0, y))\n",
        "\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)\n",
        "test_ds = test_ds.prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "yyZ2A6L9V3vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = Input(shape=(128, 128, 3))\n",
        "\n",
        "x = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(2)(x)\n",
        "\n",
        "x = Conv2D(64, 3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(2)(x)\n",
        "\n",
        "x = Conv2D(128, 3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(2)(x)\n",
        "\n",
        "x = Conv2D(256, 3, activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D(2)(x)\n",
        "\n",
        "# Reshape for RNN\n",
        "x = tf.keras.layers.Reshape((8, 256*8))(x)\n",
        "x = GRU(256, return_sequences=False)(x)\n",
        "\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs, outputs)\n",
        "model.compile(optimizer=Adam(1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "RLnnXPT-V508"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint('best_goat_crnn_model.keras', monitor='val_accuracy', save_best_only=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stop, checkpoint, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "id": "4-ayL40sV7nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"/content/drive/MyDrive/Goat_CRNN_Model.keras\"\n",
        "model.save(MODEL_PATH)\n",
        "print(\"âœ… Model saved successfully\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"ðŸ”¥ Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "# Confusion matrix\n",
        "y_true, y_pred = [], []\n",
        "for x, y in test_ds:\n",
        "    preds = model.predict(x)\n",
        "    y_true.extend(np.argmax(y.numpy(), axis=1))\n",
        "    y_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "cm = tf.math.confusion_matrix(y_true, y_pred)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(cm, xticklabels=class_names, yticklabels=class_names, cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Izp2ru6GV9tN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_PATH = \"/content/drive/MyDrive/test_image/goat_test1.png\"\n",
        "\n",
        "# Load model\n",
        "model = tf.keras.models.load_model(MODEL_PATH)\n",
        "print(\"âœ… Model loaded successfully\")\n",
        "\n",
        "# Load & preprocess image\n",
        "img = tf.keras.preprocessing.image.load_img(IMAGE_PATH, target_size=IMG_SIZE)\n",
        "img_arr = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "img_arr = np.expand_dims(img_arr, axis=0)\n",
        "\n",
        "# Predict\n",
        "pred = model.predict(img_arr)\n",
        "idx = np.argmax(pred[0])\n",
        "predicted_class = class_names[idx]\n",
        "confidence = np.max(pred[0]) * 100\n",
        "status = \"HEALTHY âœ…\" if \"healthy\" in predicted_class.lower() else \"DISEASED âŒ\"\n",
        "\n",
        "# Show result\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"{predicted_class}\\n{status} ({confidence:.2f}%)\")\n",
        "plt.show()\n",
        "\n",
        "print(\"Predicted Class :\", predicted_class)\n",
        "print(\"Status          :\", status)\n",
        "print(f\"Confidence      : {confidence:.2f}%\")\n"
      ],
      "metadata": {
        "id": "2Hc_80rwV_10"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}